{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a2435f",
   "metadata": {},
   "source": [
    "# ðŸ› ï¸ Function/Tool Calling with OpenAI  \n",
    "\n",
    "In this notebook youâ€™ll learn how to connect LLMs to **external tools and APIs**.  \n",
    "Instead of only generating text, the model can:  \n",
    "- Decide when to call a tool (e.g., weather, FX, web search).  \n",
    "- Pass structured arguments to your function.  \n",
    "- Receive back results (JSON, text, numbers, etc.).  \n",
    "- Combine tool outputs into a final, natural-language answer.  \n",
    "\n",
    "Weâ€™ll explore step-by-step:  \n",
    "1. **Basic tool calls** â€” define a schema and inspect results.  \n",
    "2. **Dummy backends** â€” simulate weather/FX lookups.  \n",
    "3. **Parallel tool calls** â€” model chooses multiple tools at once.  \n",
    "4. **Real APIs** â€” Open-Meteo for weather, ExchangeRate API for FX.  \n",
    "5. **Web search** â€” using DuckDuckGo / Tavily for live information.  \n",
    "6. **Multiple tools together** â€” model selects which tool(s) to use.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838756c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanmaydhote/Documents/src/ai-accelerator-walmart-scratch/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import json, requests, ast, os, operator as op\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d4edb",
   "metadata": {},
   "source": [
    "## 1) Defining and Using a Simple Tool  \n",
    "\n",
    "This example shows the **basics of function calling** with an LLM.  \n",
    "\n",
    "1. **Define a tool schema** â€” tell the model what function exists (`get_weather`), what it does, and the arguments it requires (JSON Schema).  \n",
    "2. **Call the model with the tool available** â€” we pass a natural language question (â€œWhat is weather in Paris?â€). The model can either answer directly in text or decide to call the tool.  \n",
    "3. **Inspect the response** â€” if the model chooses to call the tool, the call appears in `response.choices[0].message.tool_calls`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c17e97cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jN2AJahy5JMeLVpFyngRJOTm', function=Function(arguments='{\"city\":\"Paris\"}', name='get_weather'), type='function')])\n",
      "ChatCompletionMessage(content='The primary language spoken in Paris is French.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1) Define the tool schema ----------\n",
    "# Define a tool that the model can \"call\" when it needs weather info.\n",
    "# This tells the model:\n",
    "# - tool name (\"get_weather\")\n",
    "# - description (helps the model know when to use it)\n",
    "# - parameters (what arguments the tool expects, in JSON Schema form)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",       \n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City for which to get the current weather, e.g. Paris\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"city\"                # city argument is mandatory\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# ---------- 2)  Model call ----------\n",
    "# We ask the model a natural-language question.\n",
    "# Because we provide `tools=tools`, the model has the option to respond\n",
    "# either with a normal text answer OR by calling the tool.\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is weather in Paris?\"\n",
    "        }\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# ---------- 3) Inspect the result ----------\n",
    "# The model may decide to call the tool, in which case\n",
    "# `response.choices[0].message.tool_calls` will contain that request.\n",
    "# For now we just print the raw message to see what the model chose.\n",
    "print(response.choices[0].message)\n",
    "\n",
    "# ---------- 4) Model call with a query that doesn't require a tool----------\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is language spoken in Paris?\"\n",
    "        }\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# ---------- 5) Inspect the result ----------\n",
    "# We just print the raw message to see what the model chose.\n",
    "print(response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aef646",
   "metadata": {},
   "source": [
    "## 2) Handling a Tool Call with a Dummy Function  \n",
    "\n",
    "In the previous step, the model could *decide* to call a tool (`get_weather`).  \n",
    "Now weâ€™ll **simulate a backend** by:  \n",
    "1. Defining a simple Python function `get_weather` that returns static results.  \n",
    "2. Detecting when the model calls the tool.  \n",
    "3. Running our dummy function to produce the output.  \n",
    "4. Sending the toolâ€™s result back to the model so it can give a final answer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b28f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Paris is 15Â°C with cloudy skies.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ---------- 1) Define a dummy weather lookup ----------\n",
    "def get_weather(city: str) -> str:\n",
    "    # Pretend this is a weather database\n",
    "    weather_data = {\n",
    "        \"Paris\": \"15Â°C, cloudy\",\n",
    "        \"London\": \"10Â°C, rainy\",\n",
    "        \"New York\": \"22Â°C, sunny\"\n",
    "    }\n",
    "    return weather_data.get(city, \"Weather data not available\")\n",
    "\n",
    "# ---------- 2) Ask the model (same as 1A) ----------\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City for which to get the current weather, e.g. Paris\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is weather in Paris?\"}\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# ---------- 3) Inspect if tool was called ----------\n",
    "message = response.choices[0].message\n",
    "\n",
    "if message.tool_calls:\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name == \"get_weather\":\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            city = args[\"city\"]\n",
    "\n",
    "            # Run the dummy function\n",
    "            result = get_weather(city)\n",
    "\n",
    "            # ---------- 4) Send the result back to the model ----------\n",
    "            followup = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": \"What is weather in Paris?\"},\n",
    "                    message,  # include the original tool call\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": result\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            print(followup.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2894e31",
   "metadata": {},
   "source": [
    "## 3) Parallel Tool Calls (Comparing Cities)  \n",
    "\n",
    "The model isnâ€™t limited to calling a tool once â€” it can request **multiple tool calls in parallel**.  \n",
    "In this example, we ask: *â€œCompare Paris vs London weather and recommend one for a picnic.â€*  \n",
    "\n",
    "- The model issues two tool calls (`get_weather` for Paris and London).  \n",
    "- We execute each dummy lookup and return their results.  \n",
    "- A second model call combines the outputs into a natural-language comparison and recommendation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da8543ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the current weather conditions:\n",
      "\n",
      "- **Paris**: 15Â°C, cloudy\n",
      "- **London**: 10Â°C, rainy\n",
      "\n",
      "Given these conditions, Paris would be the better choice for a picnic. The temperature is warmer, and although it is cloudy, it is not raining. In contrast, London is cooler and experiencing rain, which would not be ideal for outdoor activities like a picnic. Enjoy your time in Paris!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ---------- 1) Define a dummy weather lookup ----------\n",
    "def get_weather(city: str) -> str:\n",
    "    # Pretend this is a weather database\n",
    "    weather_data = {\n",
    "        \"Paris\": \"15Â°C, cloudy\",\n",
    "        \"London\": \"10Â°C, rainy\",\n",
    "        \"New York\": \"22Â°C, sunny\"\n",
    "    }\n",
    "    return weather_data.get(city, \"Weather data not available\")\n",
    "\n",
    "# --- Tool schema (function calling) ---\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City name, e.g., Paris\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Initial prompt: compare two cities and recommend one for a picnic ---\n",
    "user_prompt = \"Compare Paris vs London weather and recommend one for a picnic.\"\n",
    "\n",
    "# First call: let the model decide to call the tool (likely twice: Paris & London)\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "first = client.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "msg = first.choices[0].message\n",
    "messages.append(msg)  # keep transcript\n",
    "\n",
    "#print(\"Output of first call: \", msg)\n",
    "\n",
    "# If the model made tool calls, run them and add results to the transcript\n",
    "if msg.tool_calls:\n",
    "    for call in msg.tool_calls:\n",
    "        if call.function.name == \"get_weather\":\n",
    "            args = json.loads(call.function.arguments or \"{}\")\n",
    "            city = args.get(\"city\", \"\")\n",
    "            result = get_weather(city)\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": call.id,\n",
    "                \"name\": \"get_weather\",\n",
    "                \"content\": result\n",
    "            })\n",
    "\n",
    "# Second call: model reads tool outputs and gives a natural-language comparison + recommendation\n",
    "#print(\"Input to second call: \", messages)\n",
    "final = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "print(final.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c27db",
   "metadata": {},
   "source": [
    "## 4) Using a Real API â€” Weather (Open-Meteo)  \n",
    "\n",
    "So far weâ€™ve used dummy lookups. Now letâ€™s connect a tool to a **real API**.  \n",
    "Here, the model calls `get_weather(city)`, which:  \n",
    "1. Uses Open-Meteoâ€™s geocoding API to find latitude/longitude.  \n",
    "2. Calls Open-Meteoâ€™s forecast API to get the current weather.  \n",
    "3. Returns structured JSON (temperature, windspeed, etc.).  \n",
    "\n",
    "The model first decides whether to call the tool.  \n",
    "If it does, we run the API function and send the result back for a final natural-language answer.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5bb1aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Dallas is 31.8Â°C with a wind speed of 8.5 km/h coming from the southeast (152Â°). It is daytime and clear weather conditions are noted.\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "# ---------- 1) Define a real weather lookup ----------\n",
    "def get_weather(city: str):\n",
    "    # Step 1: Convert city name â†’ coordinates\n",
    "    geo_resp = requests.get(\n",
    "        \"https://geocoding-api.open-meteo.com/v1/search\",\n",
    "        params={\"name\": city, \"count\": 1}\n",
    "    ).json()\n",
    "    if not geo_resp.get(\"results\"):\n",
    "        return {\"ok\": False, \"error\": \"City not found\"}\n",
    "    \n",
    "    lat = geo_resp[\"results\"][0][\"latitude\"]\n",
    "    lon = geo_resp[\"results\"][0][\"longitude\"]\n",
    "\n",
    "    # Step 2: Fetch current weather for that location\n",
    "    weather_resp = requests.get(\n",
    "        \"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\"latitude\": lat, \"longitude\": lon, \"current_weather\": True}\n",
    "    ).json()\n",
    "\n",
    "    return {\n",
    "        \"ok\": True,\n",
    "        \"city\": city,\n",
    "        \"current_weather\": weather_resp.get(\"current_weather\", {})\n",
    "    }\n",
    "\n",
    "# ---------- 2) Define tool schema ----------\n",
    "tools_weather = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# ---------- 3) Ask the model ----------\n",
    "user_query = \"Whatâ€™s the weather in Dallas right now?\"\n",
    "\n",
    "initial_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": user_query}],\n",
    "    tools=tools_weather,\n",
    "\n",
    "    # tool_choice options:\n",
    "    # - \"auto\" (default): model decides whether to call a tool or answer directly\n",
    "    # - \"none\": model is not allowed to call any tools (must answer in text)\n",
    "    # - force a specific tool: pass a dict like below\n",
    "    #   {\"type\": \"function\", \"function\": {\"name\": \"get_weather\"}}\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "assistant_message = initial_response.choices[0].message\n",
    "\n",
    "# ---------- 4) Handle tool call if present ----------\n",
    "if assistant_message.tool_calls:\n",
    "    tool_call = assistant_message.tool_calls[0]\n",
    "    call_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    # Run the real API function\n",
    "    tool_output = get_weather(call_args[\"city\"])\n",
    "\n",
    "    # Create a tool message with the API result\n",
    "    tool_message = {\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"content\": json.dumps(tool_output)\n",
    "    }\n",
    "\n",
    "    # ---------- 5) Send API result back to model ----------\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_query},\n",
    "            assistant_message,\n",
    "            tool_message\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(final_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9994118",
   "metadata": {},
   "source": [
    "## 5) Multiple Tools â€” Model Chooses (Dummy Weather + Dummy FX)\n",
    "\n",
    "Expose **two tools** at once:  \n",
    "- a dummy `get_weather(city)` lookup  \n",
    "- a dummy `get_exchange_rate(base, target)`  \n",
    "\n",
    "Ask a question that needs both (e.g., *â€œI am planning to visit Paris. How is the weather there currently? And whatâ€™s the exchange rate from USD to EUR?â€*).  \n",
    "The model decides which tool(s) to call.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d4bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of first call:  ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_A9ZRZTfGTNhoDOnpmJ41T2va', function=Function(arguments='{\"city\": \"Paris\"}', name='get_weather'), type='function'), ChatCompletionMessageToolCall(id='call_td9nzTgpI5IZ8mhVBwHvnHlF', function=Function(arguments='{\"base\": \"USD\", \"target\": \"EUR\"}', name='get_exchange_rate'), type='function')])\n",
      "Tool messages:  [{'role': 'tool', 'tool_call_id': 'call_A9ZRZTfGTNhoDOnpmJ41T2va', 'name': 'get_weather', 'content': '{\"ok\": true, \"city\": \"Paris\", \"weather\": \"18\\\\u00b0C, partly cloudy\"}'}, {'role': 'tool', 'tool_call_id': 'call_td9nzTgpI5IZ8mhVBwHvnHlF', 'name': 'get_exchange_rate', 'content': '{\"ok\": true, \"base\": \"USD\", \"target\": \"EUR\", \"rate\": 0.92}'}]\n",
      "Currently, the weather in Paris is 18Â°C and partly cloudy. \n",
      "\n",
      "As for the exchange rate, 1 USD is approximately 0.92 EUR. If you have 100 USD, you would get about 92 EUR. Enjoy your trip!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- 1) Dummy weather lookup ----------\n",
    "def get_weather(city: str):\n",
    "    weather_data = {\n",
    "        \"Paris\": \"18Â°C, partly cloudy\",\n",
    "        \"London\": \"16Â°C, rainy\",\n",
    "        \"New York\": \"22Â°C, sunny\"\n",
    "    }\n",
    "    return {\"ok\": True, \"city\": city, \"weather\": weather_data.get(city, \"Weather data not available\")}\n",
    "\n",
    "# ---------- 2) Dummy FX lookup ----------\n",
    "def get_exchange_rate(base: str, target: str):\n",
    "    fx_data = {\n",
    "        (\"USD\", \"EUR\"): 0.92,\n",
    "        (\"USD\", \"INR\"): 83.10,\n",
    "        (\"EUR\", \"INR\"): 90.15\n",
    "    }\n",
    "    rate = fx_data.get((base, target))\n",
    "    return {\"ok\": True, \"base\": base, \"target\": target, \"rate\": rate or \"Rate not available\"}\n",
    "\n",
    "# ---------- 3) Define tool schemas ----------\n",
    "tools_multi = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City, e.g., Paris\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_exchange_rate\",\n",
    "            \"description\": \"Get the current exchange rate between two currencies\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"base\": {\"type\": \"string\", \"description\": \"Base currency, e.g., USD\"},\n",
    "                    \"target\": {\"type\": \"string\", \"description\": \"Target currency, e.g., EUR\"}\n",
    "                },\n",
    "                \"required\": [\"base\", \"target\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# ---------- 4) Ask a question needing both ----------\n",
    "user_query = (\n",
    "    \"I am planning to visit Paris. How is the weather there currently? \"\n",
    "    \"And whatâ€™s the exchange rate from USD to EUR? I have 100 USD.\"\n",
    ")\n",
    "\n",
    "initial_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": user_query}],\n",
    "    tools=tools_multi,\n",
    "    tool_choice=\"auto\"   # model chooses which tool(s) to call\n",
    ")\n",
    "\n",
    "assistant_message = initial_response.choices[0].message\n",
    "print(\"Output of first call: \", assistant_message)\n",
    "\n",
    "# ---------- 5) Execute any/all tool calls ----------\n",
    "tool_messages = []\n",
    "if assistant_message.tool_calls:\n",
    "    for tool_call in assistant_message.tool_calls:\n",
    "        fn = tool_call.function.name\n",
    "        args = json.loads(tool_call.function.arguments or \"{}\")\n",
    "\n",
    "        if fn == \"get_weather\":\n",
    "            result = get_weather(args.get(\"city\", \"\"))\n",
    "        elif fn == \"get_exchange_rate\":\n",
    "            result = get_exchange_rate(args.get(\"base\", \"\"), args.get(\"target\", \"\"))\n",
    "        else:\n",
    "            result = {\"ok\": False, \"error\": f\"Unknown tool: {fn}\"}\n",
    "\n",
    "        tool_messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": fn,\n",
    "            \"content\": json.dumps(result)\n",
    "        })\n",
    "\n",
    "print(\"Tool messages: \", tool_messages)\n",
    "\n",
    "# ---------- 6) Send all tool results back ----------\n",
    "final_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": user_query}, assistant_message, *tool_messages]\n",
    ")\n",
    "\n",
    "print(final_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c5292",
   "metadata": {},
   "source": [
    "## 6) Multiple Tools â€” Model Chooses (Weather + FX)\n",
    "\n",
    "Expose **two tools** at once: a real-weather lookup (Open-Meteo) and a real FX converter (exchangerate.host).  \n",
    "Ask a single question that needs **both**. The model will issue tool calls for each, you run them, then send results back for a final response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b045058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, the weather in Paris is quite pleasant with a temperature of 24.4Â°C. The windspeed is around 4.8 km/h coming from the southwest.\n",
      "\n",
      "As for the exchange rate, 1 USD is approximately equal to 0.8588 EUR. If you have 100 USD, you would get around 85.88 EUR.\n"
     ]
    }
   ],
   "source": [
    "import json, requests\n",
    "\n",
    "# ---------- 1) Real weather lookup (Open-Meteo) ----------\n",
    "def get_weather(city: str):\n",
    "    # Step 1: name -> lat/lon\n",
    "    geo_resp = requests.get(\n",
    "        \"https://geocoding-api.open-meteo.com/v1/search\",\n",
    "        params={\"name\": city, \"count\": 1}\n",
    "    ).json()\n",
    "    if not geo_resp.get(\"results\"):\n",
    "        return {\"ok\": False, \"error\": \"City not found\"}\n",
    "    lat = geo_resp[\"results\"][0][\"latitude\"]\n",
    "    lon = geo_resp[\"results\"][0][\"longitude\"]\n",
    "\n",
    "    # Step 2: current weather\n",
    "    weather_resp = requests.get(\n",
    "        \"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\"latitude\": lat, \"longitude\": lon, \"current_weather\": True}\n",
    "    ).json()\n",
    "\n",
    "    return {\n",
    "        \"ok\": True,\n",
    "        \"city\": city,\n",
    "        \"current_weather\": weather_resp.get(\"current_weather\", {})\n",
    "    }\n",
    "\n",
    "# ---------- 2) FX rate lookup (ExchangeRate-API) ----------\n",
    "def get_exchange_rate(base: str, target: str):\n",
    "    fx_resp = requests.get(f\"https://open.er-api.com/v6/latest/{base}\").json()\n",
    "\n",
    "    if fx_resp.get(\"result\") != \"success\":\n",
    "        return {\"ok\": False, \"error\": fx_resp.get(\"error-type\", \"API call failed\")}\n",
    "    \n",
    "    rate = fx_resp.get(\"rates\", {}).get(target)\n",
    "    return {\n",
    "        \"ok\": bool(rate),\n",
    "        \"base\": base,\n",
    "        \"target\": target,\n",
    "        \"rate\": rate\n",
    "    }\n",
    "\n",
    "# ---------- 3) Declare BOTH tools to the model ----------\n",
    "tools_multi = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City, e.g., Paris\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_exchange_rate\",\n",
    "            \"description\": \"Get the current exchange rate between two currencies\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"base\": {\"type\": \"string\", \"description\": \"Base currency code, e.g., USD\"},\n",
    "                    \"target\": {\"type\": \"string\", \"description\": \"Target currency code, e.g., EUR\"}\n",
    "                },\n",
    "                \"required\": [\"base\", \"target\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# ---------- 4) Ask a single question that needs both tools ----------\n",
    "user_query = (\n",
    "    \"I am planning to visit Paris. How is the weather there currently? \"\n",
    "    \"And whatâ€™s the exchange rate from USD to EUR? I have 100 USD.\"\n",
    ")\n",
    "\n",
    "initial_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": user_query}],\n",
    "    tools=tools_multi,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "assistant_message = initial_response.choices[0].message\n",
    "\n",
    "# ---------- 5) Execute any/all tool calls ----------\n",
    "tool_messages = []\n",
    "if assistant_message.tool_calls:\n",
    "    for tool_call in assistant_message.tool_calls:\n",
    "        fn = tool_call.function.name\n",
    "        args = json.loads(tool_call.function.arguments or \"{}\")\n",
    "\n",
    "        if fn == \"get_weather\":\n",
    "            result = get_weather(args.get(\"city\", \"\"))\n",
    "        elif fn == \"get_exchange_rate\":\n",
    "            result = get_exchange_rate(args.get(\"base\", \"\"), args.get(\"target\", \"\"))\n",
    "        else:\n",
    "            result = {\"ok\": False, \"error\": f\"Unknown tool: {fn}\"}\n",
    "\n",
    "        tool_messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"name\": fn,\n",
    "            \"content\": json.dumps(result)\n",
    "        })\n",
    "\n",
    "# ---------- 6) Send all tool results back ----------\n",
    "final_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": user_query}, assistant_message, *tool_messages]\n",
    ")\n",
    "\n",
    "print(final_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914ee2d",
   "metadata": {},
   "source": [
    "## 7) Web Search Tool â€” Tavily API  \n",
    "\n",
    "You can also wire up a **web search tool**.  \n",
    "Here we connect to the Tavily Search API, which is designed for LLMs and returns a concise answer with supporting sources.  \n",
    "\n",
    "Flow:  \n",
    "1. Define `web_search(query)` â†’ calls Tavily and returns an answer + results.  \n",
    "2. Provide the tool schema to the model.  \n",
    "3. Ask a question that requires external knowledge.  \n",
    "4. If the model calls the tool, run the API call and feed results back.  \n",
    "5. Make a second model call to generate a final, natural-language answer that incorporates the search results.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7caa36c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool output:  {'answer': None, 'results': [{'title': 'Bitcoin BTC (BTC-USD) Live Price, News, Chart & Price History', 'url': 'https://finance.yahoo.com/quote/BTC-USD/', 'content': 'Bitcoin has a current supply of 19,912,209. The last known price of Bitcoin is 110,854.49673546 USD and is up 0.70 over the last 24 hours.Historical DataÂ·CommunityÂ·ChartÂ·ProShares UltraShort Bitcoin', 'score': 0.8405867}, {'title': 'Bitcoin price today, BTC to USD live price, marketcap and chart', 'url': 'https://coinmarketcap.com/currencies/bitcoin/', 'content': 'Rating4.4(3)The live Bitcoin price today is $111715.02 USD with a 24-hour trading volume of $61675436010.63 USD. We update our BTC to USD price in real-time.', 'score': 0.8342047}, {'title': 'Bitcoin (BTC) Price | BTC to USD Price and Live Chart - CoinDesk', 'url': 'https://www.coindesk.com/price/bitcoin', 'content': 'The price of Bitcoin (BTC) is $111981.50 today as of Aug 27, 2025, 3:25 pm EDT, with a 24-hour trading volume of $19.82B.Bitcoin CashÂ·EthereumÂ·PlatformsÂ·News', 'score': 0.81524754}, {'title': 'Bitcoin Price, BTC Price, Live Charts, and Marketcap - Coinbase', 'url': 'https://www.coinbase.com/price/bitcoin', 'content': \"Price of BTC is $112,051.05 right now. Looking at Bitcoin's historical prices, it's -4% down from the previous week's price of $117,648.06, and observed a -2%\", 'score': 0.79675186}, {'title': 'Bitcoin (BTC) Price Today | BTC Live Price Charts - Revolut', 'url': 'https://www.revolut.com/crypto/price/btc/', 'content': 'Rating4.6(247,659)The price of Bitcoin has increased today. 1 BTC currently costs Â£82,791.13, which represents a change of -0.14% in the last hour and a change of +1.16% in the', 'score': 0.7927375}]}\n",
      "The latest price of Bitcoin is approximately $111,715.02 USD. Prices may vary slightly between different sources, so here are a few additional references:\n",
      "\n",
      "- **CoinMarketCap:** $111,715.02 USD\n",
      "- **Coinbase:** $112,051.05 USD\n",
      "- **CoinDesk:** $111,981.50 USD\n",
      "\n",
      "For the most accurate and real-time data, you might want to check a financial news website or a cryptocurrency exchange.\n"
     ]
    }
   ],
   "source": [
    "import requests, json, os\n",
    "\n",
    "# ---------- 1) Define Tavily web search ----------\n",
    "#NOTE:\n",
    "# Most reliable web search providers (SerpAPI, DuckDuckGo Search API, Perplexity, Tavily, etc.)\n",
    "# require an API key â€” they are paid/freemium services.\n",
    "# For now, you can use the instructorâ€™s key, but for production use\n",
    "# you will need to bring your own key from the providerâ€™s dashboard.\n",
    "\n",
    "def web_search(query: str):\n",
    "    \"\"\"Call Tavily Search API and return summary + sources.\"\"\"\n",
    "    resp = requests.post(\n",
    "        \"https://api.tavily.com/search\",\n",
    "        headers={\"Authorization\": \"Bearer \"API-KEY\"},\n",
    "        json={\"query\": query, \"max_results\": 5}   # keep it concise\n",
    "    ).json()\n",
    "\n",
    "    return {\n",
    "        \"answer\": resp.get(\"answer\"),\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"title\": r.get(\"title\"),\n",
    "                \"url\": r.get(\"url\"),\n",
    "                \"content\": r.get(\"content\"),\n",
    "                \"score\": r.get(\"score\")\n",
    "            }\n",
    "            for r in resp.get(\"results\", [])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ---------- 2) Define tool schema ----------\n",
    "tools_search = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"web_search\",\n",
    "            \"description\": \"Perform a web search and return summary + sources\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# ---------- 3) Ask a question ----------\n",
    "user_query = \"What is the latest bitcoin price?â€\"\n",
    "\n",
    "initial_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": user_query}],\n",
    "    tools=tools_search,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "assistant_message = initial_response.choices[0].message\n",
    "\n",
    "# ---------- 4) Run the tool if model calls it ----------\n",
    "if assistant_message.tool_calls:\n",
    "    tool_call = assistant_message.tool_calls[0]\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    tool_output = web_search(args[\"query\"])\n",
    "    print(\"Tool output: \", tool_output)\n",
    "    tool_message = {\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": \"web_search\",\n",
    "        \"content\": json.dumps(tool_output)\n",
    "    }\n",
    "\n",
    "    # ---------- 5) Send tool result back ----------\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_query},\n",
    "            assistant_message,\n",
    "            tool_message\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(final_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efa9a3",
   "metadata": {},
   "source": [
    "## ðŸŸ£ Bonus â€” OpenAI Built-in Tools (Responses API)\n",
    "\n",
    "> âš ï¸ **Do Not Use Yet**  \n",
    "> Weâ€™re waiting for access to the new **Responses API** endpoint on Azure OpenAI.  \n",
    "> This is the only endpoint that will provide direct access to OpenAIâ€™s **built-in tools**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client_resp = OpenAI()\n",
    "\n",
    "# Web search (built-in tool)\n",
    "resp_ws = client_resp.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"What was Walmartâ€™s latest quarterly revenue?\"}],\n",
    "    tools=[{\"type\":\"web_search\"}]\n",
    ")\n",
    "print(\"WEB SEARCH RESULT:\\n\", resp_ws.output_text)\n",
    "\n",
    "# Code interpreter (built-in tool)\n",
    "resp_ci = client_resp.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Calculate the 3-month moving average of [120,150,90,200,130].\"}],\n",
    "    tools=[{\"type\":\"code_interpreter\"}]\n",
    ")\n",
    "print(\"CODE INTERPRETER RESULT:\\n\", resp_ci.output_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
