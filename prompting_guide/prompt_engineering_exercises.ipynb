{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef774791",
   "metadata": {},
   "source": [
    "# Prompt Engineering — Hands‑On Exercises (Runnable)\n",
    "\n",
    "This notebook contains six practical exercises.\n",
    "\n",
    "1. Improve the Prompt – Be Clear, Direct, Specific\n",
    "2. Improve the Prompt – Avoid Impreciseness\n",
    "3. Zero-Shot vs Few-Shot Prompting\n",
    "4. Role Prompting\n",
    "5. Chain of Thought (CoT) Prompt\n",
    "6. Prompt Chaining\n",
    "\n",
    "## How to use the notebook\n",
    "1) Complete the `get_completion` helper \n",
    "2) Fill in the relevant snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbabbb",
   "metadata": {},
   "source": [
    "## 0) Setup (OpenAI client + tiny helper)\n",
    "\n",
    "- Set up the environment and complete the get_completion() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f73d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLM helper: edit this to use your preferred SDK ===\n",
    "\n",
    "\n",
    "def get_completion(prompt: str, **gen_kwargs) -> str:\n",
    "  # Fill this up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be92f0",
   "metadata": {},
   "source": [
    "## 1) Improve the prompt — Be clear, direct, and specific\n",
    "\n",
    "**Given (vague):** `Tell me something about Paris.`\n",
    "\n",
    "**Task:** Rewrite it into a clear, specific instruction. Write **two** variants that differ in audience/constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prompt = \"Tell me something about Paris.\"\n",
    "improved_prompt = \"\"\n",
    "\n",
    "print(get_completion(original_prompt))\n",
    "print('\\n---\\n')\n",
    "print(get_completion(improved_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcbf80",
   "metadata": {},
   "source": [
    "## 2) Improve the prompt — Avoid impreciseness\n",
    "\n",
    "**Given (imprecise):** `Write a short story for kids.`\n",
    "\n",
    "**Task:** Rewrite it with precise details (age, theme, tone, length, constraints). Provide **two** alternatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prompt = \"Write a short story for kids.\"\n",
    "precise_prompt = \"\"\n",
    "\n",
    "print(get_completion(original_prompt))\n",
    "print('\\n---\\n')\n",
    "print(get_completion(precise_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7452c5b",
   "metadata": {},
   "source": [
    "## 3) Zero‑shot vs Few‑shot prompting (Sentiment)\n",
    "\n",
    "Classify the sentiment of this review: **\"The phone battery dies in 2 hours.\"**\n",
    "\n",
    "- **Zero‑shot:** ask directly.\n",
    "- **Few‑shot:** provide labeled examples, then classify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"The phone battery dies in 2 hours.\"\n",
    "\n",
    "# Zero‑shot\n",
    "zero_shot_prompt = \"\"\n",
    "\n",
    "\n",
    "print(get_completion(zero_shot_prompt))\n",
    "\n",
    "print('\\n===\\n')\n",
    "\n",
    "# Few‑shot\n",
    "few_shot_prompt = \"\"\n",
    "print(get_completion(few_shot_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b6127",
   "metadata": {},
   "source": [
    "## 4) Role prompting\n",
    "\n",
    "Write two prompts:\n",
    "- One **professional** role (e.g., analyst, teacher, support agent)\n",
    "- One **creative** role (e.g., chef, poet, travel guide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_prompt_professional = \"\"\n",
    "role_prompt_creative = \"\"\n",
    "\n",
    "print(get_completion(role_prompt_professional))\n",
    "print('\\n---\\n')\n",
    "print(get_completion(role_prompt_creative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f99e06",
   "metadata": {},
   "source": [
    "## 5) Chain of Thought (CoT) — Real‑world business problem\n",
    "\n",
    "**Problem:** `Walmart had $1.2M sales in January. Sales increased 20% in February, then decreased 10% in March. What were March sales?`\n",
    "\n",
    "**Task:** Ask the model to **think step by step** and show calculations before giving the final number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem =  \"\"\"Walmart had $1.2M sales in January. Sales increased 20% in February, then decreased 10% in March. What were March sales?\"\"\"\n",
    "\n",
    "# Fill in your Chain of Thought (CoT) prompt here\n",
    "cot_prompt = \"\"\n",
    "\n",
    "print(get_completion(cot_prompt, temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a92b5",
   "metadata": {},
   "source": [
    "## 6) Prompt chaining\n",
    "\n",
    "**Task:** Break a task into two more sequential prompts\n",
    "\n",
    "**Example Flow:**\n",
    "1) Summarize a product review into 3 bullets (<=10 words each)\n",
    "2) Generate a catchy headline from the summary (<=12 words)\n",
    "\n",
    "Now design your own chained prompts for a task of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b663a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Notebook updated on 2025-08-25 03:36 UTC.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
