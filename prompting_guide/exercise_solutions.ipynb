{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, ValidationError, field_validator\n",
    "from typing import List, Literal, Optional\n",
    "import os,json, textwrap, base64\n",
    "\n",
    "# Optional: set your key here for local testing (avoid committing real keys)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display_html\n",
    "\n",
    "# Local paths (replace with your generated/saved before & after image paths)\n",
    "before_img = \"shelf_before.png\"\n",
    "after_img = \"shelf_after.png\"\n",
    "\n",
    "# ---- Display side-by-side in notebook ----\n",
    "display_html(f\"\"\"\n",
    "<div style=\"display:flex; gap:20px;\">\n",
    "  <div><h4>Before</h4><img src=\"{before_img}\" width=\"300\"></div>\n",
    "  <div><h4>After</h4><img src=\"{after_img}\" width=\"300\"></div>\n",
    "</div>\n",
    "\"\"\", raw=True)\n",
    "\n",
    "\n",
    "# ---- Convert both local images to base64 data URLs ----\n",
    "def to_data_url(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "before_data_url = to_data_url(before_img)\n",
    "after_data_url = to_data_url(after_img)\n",
    "\n",
    "# ---- Send to Vision model for comparison ----\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_VISION,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Compare the shelves before and after restocking. Highlight changes in 3 concise bullets.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": before_data_url}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": after_data_url}}\n",
    "        ]\n",
    "    }],\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ProsCons(BaseModel):\n",
    "    pros: List[str]\n",
    "    cons: List[str]\n",
    "    justifications: List[str]  # 1:1 with pros+cons in order\n",
    "\n",
    "instruction = f\"\"\"\n",
    "Extract pros and cons from the review.\n",
    "\n",
    "Rules:\n",
    "- Detect sarcasm/irony. If a positive-sounding phrase implies a negative, classify as a con.\n",
    "- A \"pro\" must be a REAL benefit to a buyer. If none, return an empty pros list.\n",
    "- Do NOT include joke/ironic \"benefits\" (e.g., calling a broken phone a good paperweight).\n",
    "- For every item, include a short justification phrase quoted from the review.\n",
    "- Return only JSON matching the schema.\n",
    "Review: {review}\n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\":\"user\",\"content\":instruction}],\n",
    "    temperature=0,\n",
    "    response_format=ProsCons\n",
    ")\n",
    "data = resp.choices[0].message.parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "# --- Dummy tool backend ---\n",
    "def get_weather(city: str) -> str:\n",
    "    data = {\n",
    "        \"Paris\":  \"18¬∞C, partly cloudy, light breeze\",\n",
    "        \"London\": \"16¬∞C, light rain, breezy\",\n",
    "    }\n",
    "    return data.get(city, \"Weather data not available\")\n",
    "\n",
    "# --- Tool schema (function calling) ---\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\"type\": \"string\", \"description\": \"City name, e.g., Paris\"}\n",
    "                },\n",
    "                \"required\": [\"city\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- Initial prompt: compare two cities and recommend one for a picnic ---\n",
    "user_prompt = \"Compare Paris vs London weather and recommend one for a picnic.\"\n",
    "\n",
    "# First call: let the model decide to call the tool (likely twice: Paris & London)\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "first = client.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "msg = first.choices[0].message\n",
    "messages.append(msg)  # keep transcript\n",
    "\n",
    "# If the model made tool calls, run them and add results to the transcript\n",
    "if msg.tool_calls:\n",
    "    for call in msg.tool_calls:\n",
    "        if call.function.name == \"get_weather\":\n",
    "            args = json.loads(call.function.arguments or \"{}\")\n",
    "            city = args.get(\"city\", \"\")\n",
    "            result = get_weather(city)\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": call.id,\n",
    "                \"name\": \"get_weather\",\n",
    "                \"content\": result\n",
    "            })\n",
    "\n",
    "# Second call: model reads tool outputs and gives a natural-language comparison + recommendation\n",
    "final = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "print(final.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß© Exercises ‚Äî Function Calling\n",
    "\n",
    "### Exercise 1: Chained Reasoning ‚Äî Weather ‚Üí Plan Recommendation  \n",
    "Ask:  \n",
    "> ‚ÄúI‚Äôm visiting Paris today. Based on the **current weather**, should I plan an **outdoor run** or go to an **indoor gym**?‚Äù  \n",
    "\n",
    "Do it in two steps:  \n",
    "1. Call the weather tool to get `temperature` and `windspeed`.\n",
    "2. Make a **second model call** that applies this policy to the tool output:  \n",
    "   - If `temperature < 12¬∞C` OR `windspeed ‚â• 25 km/h` OR if it's raining‚Üí **INDOOR GYM**  \n",
    "   - Otherwise ‚Üí **OUTDOOR RUN**  \n",
    "\n",
    "Have the model return:  \n",
    "- **decision** (OUTDOOR RUN / INDOOR GYM)  \n",
    "- **justification** citing the exact numbers (e.g., ‚Äú10¬∞C, 28 km/h wind‚Äù)  \n",
    "- a **3-item checklist** (e.g., jacket, water, shoes for gym/run)  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2: Multi-Tool Orchestration ‚Äî Paris Trip Planner  \n",
    "A traveler asks:  \n",
    "> ‚ÄúI‚Äôm planning a trip to Paris. What‚Äôs the weather like, what‚Äôs the USD‚ÜíEUR exchange rate, and can you recommend a book set in Paris to get into the vibe?‚Äù  \n",
    "\n",
    "Tools involved:  \n",
    "- **Weather API (Open-Meteo)** ‚Üí helps plan what to wear.  \n",
    "- **Currency Exchange API (ExchangeRate-API)** ‚Üí helps plan the budget.  \n",
    "- **Books API (OpenLibrary)** ‚Üí suggests a book to set the mood for the journey.  \n",
    "\n",
    "**Your task:**  \n",
    "- Combine all three tools.  \n",
    "- Feed tool results back to the model for a final natural-language answer.  \n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3: Product Price Checker + Inventory Tracker  \n",
    "A store manager asks:  \n",
    "> ‚ÄúDo we have Nike Air Max in stock, and what‚Äôs the current online price?‚Äù  \n",
    "\n",
    "Tools involved:  \n",
    "- **Inventory API** ‚Üí check stock count in local warehouse.  \n",
    "- **Pricing API (or Web Search)** ‚Üí fetch competitor/market price.  \n",
    "\n",
    "**Your task:**  \n",
    "- Define your own **dummy functions** for both tools (e.g., one dictionary for stock, another for prices).  \n",
    "- Expose both tools to the model.  \n",
    "- Ask the scenario question and observe that the model calls *both tools*.  \n",
    "- Feed the tool results back so the model synthesizes a useful final answer.  \n",
    "\n",
    "üí° *Extension:* Expand your dummy data with multiple products or warehouses so the query can be richer than just ‚ÄúNike Air Max.‚Äù .  \n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 4: Open-Ended Multi-Tool Scenario  \n",
    "Now it‚Äôs your turn.  \n",
    "\n",
    "- Think of a **real-world scenario** where an assistant would need to combine **at least two tools**.  \n",
    "- Define which APIs/tools you would connect.  \n",
    "- Write the natural-language query a user might ask.  \n",
    "- Sketch how the model would break it down into tool calls and then combine the answers.  \n",
    "\n",
    "P.S. - If you cannot find a free API for your use-case here, just define a dummy function to return the results. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
