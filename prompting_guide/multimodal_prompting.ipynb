{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5527413",
   "metadata": {},
   "source": [
    "\n",
    "# Multimodal Prompting\n",
    "\n",
    "**What you'll explore**\n",
    "- How to prompt *vision models* with **image URLs** and **local files**.\n",
    "- Examples:\n",
    "    - scene description\n",
    "    - shelf stock checks\n",
    "    - extracting info from receipts\n",
    "    - interpreting sales charts\n",
    "    - filtering menus / labels\n",
    "\n",
    "**Exercises**\n",
    "\n",
    "At the end of the notebook, you‚Äôll find 4 exercises to practice these skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ab61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import base64, os, json\n",
    "\n",
    "# Optional: set your key here for local testing (avoid committing real keys)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" \n",
    "\n",
    "client = OpenAI()\n",
    "MODEL_VISION = \"gpt-4o\"          # Vision-capable\n",
    "MODEL_FAST = \"gpt-4o-mini\"       # Cheaper/faster text model (used later if needed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f676a",
   "metadata": {},
   "source": [
    "## 1) Describe a scene (Image URL)\n",
    "Working with image inputs and generating detailed visual descriptions.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad012d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1b/Cycling_12.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a scenic outdoor setting with two cyclists riding on a paved road. The foreground features a cyclist wearing a helmet, a white and red cycling jersey, and black shorts. The cyclist is riding a road bike and is positioned on the left side of the image. A number is visible on the bike, suggesting participation in an event or race.\n",
      "\n",
      "In the background, another cyclist is visible further down the road. The road curves gently to the right and is bordered by grass and small plants. The landscape is characterized by rolling hills with patches of grass and rocky outcrops. A stone wall runs along the hillside on the left.\n",
      "\n",
      "The sun is shining brightly, casting long shadows of the cyclists on the road. The sky is clear, contributing to the overall bright and serene atmosphere of the scene. The lighting suggests it might be early morning or late afternoon.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# ---------- 1) Show the image inline in a notebook ----------\n",
    "# Set the image URL you want to display\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/1/1b/Cycling_12.jpg\"\n",
    "\n",
    "# Display the image inside the notebook (so you can visually confirm it)\n",
    "display(Image(url=image_url))  \n",
    "\n",
    "\n",
    "# ---------- 2) Send the image to the model with a text instruction ----------\n",
    "# We call the Vision-capable model (MODEL_VISION must support image inputs).\n",
    "# The `messages` array contains one user message with *two parts*:\n",
    "#   - a text instruction (\"Describe the image in detail\")\n",
    "#   - the actual image (via image_url)\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_VISION,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Describe the image in detail\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "        ]\n",
    "    }],\n",
    "    temperature=0.2   # Lower temp = more deterministic description\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- 3) Read the model‚Äôs description ----------\n",
    "# The model‚Äôs answer comes back as natural language text\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a9804",
   "metadata": {},
   "source": [
    "## 2) Shelf Check (Image URL)\n",
    "Analyzing images to detect patterns or conditions in real-world scenes - Identify **low/empty** spots and name categories if visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca82f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f0/Milk_shelf_at_Singapore_supermarket.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Bottom Shelf (Right Side):** The area appears empty, likely meant for juice or milk products.\n",
      "- **Middle Shelf (Right Side):** Low stock of bottled drinks, possibly flavored milk or coffee.\n",
      "- **Bottom Shelf (Left Side):** Low stock of large milk cartons or bottles.\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/f0/Milk_shelf_at_Singapore_supermarket.png\"\n",
    "# Alternate demo image:\n",
    "# image_url = \"https://gibsonretail.com.au/wp-content/uploads/2023/03/Shelving-Systems_Outrigger-Shelving_Intro-Image-1.jpg\"\n",
    "\n",
    "# Display the chosen image inline\n",
    "display(Image(url=image_url))  \n",
    "\n",
    "# Ask the vision model to check shelves for low/empty stock\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_VISION,\n",
    "    messages=[{\n",
    "        \"role\":\"user\",\n",
    "        \"content\":[\n",
    "            {\"type\":\"text\",\"text\":\"Identify any low-stock or empty areas and name the product categories if visible. Keep it to 3 bullets.\"},\n",
    "            {\"type\":\"image_url\",\"image_url\":{\"url\": image_url}}\n",
    "        ]\n",
    "    }],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Print the model response\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789cb1c5",
   "metadata": {},
   "source": [
    "## 3) Receipt Extraction (Local File)\n",
    "Upload a **local receipt** and extract **store, date, total**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7940ea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"receipt_1.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Store Name:** The Tack Room\n",
      "- **City/State:** Lincoln, MA\n",
      "- **Date:** 4/8/24\n",
      "- **Items Ordered:**\n",
      "  1. BBQ Potato Chips - $7.00\n",
      "  2. Diet Coke - $3.00\n",
      "  3. Trillium Fort Point - $10.00\n",
      "  4. Fried Chicken Sandwich - $14.00\n",
      "  5. Famous Duck Grilled Cheese - $25.00\n",
      "  6. Mac & Cheese - $12.00\n",
      "  7. Burger of the Moment - $16.00\n",
      "- **Total Amount:** $124.53\n"
     ]
    }
   ],
   "source": [
    "local_image_path = \"receipt_1.jpeg\"  # <- replace with a real file on your machine\n",
    "local_image_path_1 = \"receipt_2.jpeg\"  # <- handwritten receipt\n",
    "# Display the local image in the notebook\n",
    "display(Image(url=local_image_path))  \n",
    "\n",
    "try:\n",
    "    # Convert image bytes ‚Üí base64 ‚Üí data URL (so it can be passed inline)\n",
    "    with open(local_image_path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    data_url = f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "    # Ask the vision model to parse key details from the receipt\n",
    "    resp2 = client.chat.completions.create(\n",
    "        model=MODEL_VISION,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Extract store name, city/state if visible, date, items ordered and total amount.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n",
    "            ]\n",
    "        }],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    print(resp2.choices[0].message.content)\n",
    "\n",
    "# Handle the case where the file path is invalid or the image is missing\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Set local_image_path to a real image before running.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472863eb",
   "metadata": {},
   "source": [
    "## 4) Menu/Label Filter (Image URL)\n",
    "Demonstrates how to query an image while applying constraints ‚Äî for example, filtering menu items that are vegetarian and under a given price. (e.g., vegetarian under $5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b4e96af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://renderer.mhmcdn.com/design/thumbnail/34913cd4-8611-42ac-b942-b4ab1c42e2f4?width=500&update=1756292135305\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vegetarian items priced under $6 are:\n",
      "\n",
      "- Sweet Potato Fries - $4.95\n",
      "- Breadstick & Sauce - $4.95\n"
     ]
    }
   ],
   "source": [
    "menu_img = \"https://renderer.mhmcdn.com/design/thumbnail/34913cd4-8611-42ac-b942-b4ab1c42e2f4?width=500&update=1756292135305\"  # example menu image\n",
    "\n",
    "# Display the menu image in the notebook\n",
    "display(Image(url=menu_img))  \n",
    "\n",
    "# Ask the vision model to read the menu and apply a logical filter\n",
    "resp4 = client.chat.completions.create(\n",
    "    model=MODEL_VISION,\n",
    "    messages=[{\n",
    "        \"role\":\"user\",\n",
    "        \"content\":[\n",
    "            {\"type\":\"text\",\"text\":\"From this menu, list vegetarian items priced under $6.\"},\n",
    "            {\"type\":\"image_url\",\"image_url\":{\"url\": menu_img}}\n",
    "        ]\n",
    "    }],\n",
    "    temperature=0.2  \n",
    ")\n",
    "\n",
    "# Print the model‚Äôs filtered list of menu items\n",
    "print(resp4.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2289525",
   "metadata": {},
   "source": [
    "## 5) Sales Chart Interpretation (Image URL)\n",
    "Summarize the **trend** in 2 bullets.\n",
    "Use a chart image as input and have the model summarize visible trends concisely. LLMs can interpret graphs and plots too.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467d5353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.thesaascfo.com/wp-content/uploads/2017/05/Committed-Monthly-Recurring-Revenue-Chart.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Steady MRR growth from $1,055,000 to $2,348,000 over 12 months.\n",
      "- New business consistently contributes to revenue increase each month.\n",
      "- Upsells enhance revenue, maintaining upward trend.\n",
      "- Minimal impact from downgrades and churn on overall growth.\n",
      "- CMRR shows a positive, consistent upward trajectory.\n"
     ]
    }
   ],
   "source": [
    "chart_url = \"https://www.thesaascfo.com/wp-content/uploads/2017/05/Committed-Monthly-Recurring-Revenue-Chart.png\"\n",
    "\n",
    "# Display the sales chart in the notebook\n",
    "display(Image(url=chart_url))  \n",
    "\n",
    "# Ask the vision model to interpret the revenue trend in concise bullet points\n",
    "resp3 = client.chat.completions.create(\n",
    "    model=MODEL_VISION,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Explain the revenue trend in 5 concise bullets (<=15 words each).\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": chart_url}}\n",
    "        ]\n",
    "    }],\n",
    "    temperature=0.3  # slight randomness for varied phrasing\n",
    ")\n",
    "\n",
    "# Print the model‚Äôs summary of the chart trend\n",
    "print(resp3.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955117c",
   "metadata": {},
   "source": [
    "# üñº Exercises ‚Äî Multimodal Prompting\n",
    "\n",
    "### Exercise 1: Chart Analysis  \n",
    "Use the revenue chart provided - https://www.thesaascfo.com/wp-content/uploads/2017/05/Committed-Monthly-Recurring-Revenue-Chart.png.  \n",
    "- Summarize the trend in **2 bullets**: one on growth, one on driver composition.  \n",
    "- Then, explain the same chart to a **10-year-old in 2 simple sentences**.  \n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 2: GST Invoice Extraction  \n",
    "You‚Äôre given a GST tax invoice image - https://www.outputbooks.com/wp-content/themes/outputbooks/images/oub_GST_Invoice_Format.png.  \n",
    "- Extract the **invoice number, invoice date, and due date**.  \n",
    "- Extract the **seller details** (company, address, GSTIN) and **buyer details** (name, address, GSTIN, contact).  \n",
    "- Extract all **line items** (name, manufacturing date, quantity, rate, tax, amount).  \n",
    "- Extract the **subtotal and grand total**.  \n",
    "- Capture the **amount in words** if present.  \n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 3: Spot the Difference ‚Äî Shelf Changes  \n",
    "You‚Äôre given a **before** and **after** shelf image.  \n",
    "- Compare the two.  \n",
    "- Highlight the changes in **3 concise bullets**.  \n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 4: Design Your Own Multimodal Scenario  \n",
    "Think of a situation where combining **image + text prompting** could help.  \n",
    "- Write your own prompt.  \n",
    "- Test it with a relevant image.  \n",
    "- Share your result.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
