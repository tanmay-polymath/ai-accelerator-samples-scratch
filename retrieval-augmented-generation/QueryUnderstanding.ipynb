{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34ce3d6",
   "metadata": {},
   "source": [
    "## Notebook on Query Understanding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04192d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eee56c",
   "metadata": {},
   "source": [
    "## Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2029e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " You are a helpful assistant that generates multiple search queries based on a single input query.\n",
      "\n",
      "Perform query expansion. If there are multiple common ways of phrasing a user question\n",
      "or common synonyms for key words in the question, make sure to return multiple versions\n",
      "of the query with the different phrasings.\n",
      "\n",
      "If there are acronyms or words you are not familiar with, do not try to rephrase them.\n",
      "\n",
      "Return 3 different versions of the question.\n",
      "\n",
      "    Original query: dress for wedding\n",
      "\n",
      "    Rewritten query:\n",
      "\n",
      "OpenAI response: content='1. Outfit for wedding\\n2. Attire for wedding ceremony\\n3. Clothing for wedding event' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 113, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CQ4DnOrkPgBBwVM3rebk6OFizuvHo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--c3de5414-6511-480d-9769-ecfa58c777bc-0' usage_metadata={'input_tokens': 113, 'output_tokens': 21, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Create a simple prompt template\n",
    "template = \"\"\"\n",
    " You are a helpful assistant that generates multiple search queries based on a single input query.\n",
    "\n",
    "Perform query expansion. If there are multiple common ways of phrasing a user question\n",
    "or common synonyms for key words in the question, make sure to return multiple versions\n",
    "of the query with the different phrasings.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\n",
    "\n",
    "Return 3 different versions of the question.\n",
    "\n",
    "    Original query: {original_query}\n",
    "\n",
    "    Rewritten query:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "query = \"dress for wedding\"\n",
    "\n",
    "# Use the prompt template\n",
    "result = prompt.format(original_query=query)\n",
    "print(result)\n",
    "\n",
    "print(\"OpenAI response:\", llm.invoke(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3326ed7",
   "metadata": {},
   "source": [
    "## Query Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadd44f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " You are a helpful assistant that generates search queries based on a single input query.\n",
      "\n",
      "Perform query decomposition. Given a user question, break it down into distinct sub questions that\n",
      "you need to answer in order to answer the original question.\n",
      "\n",
      "If there are acronyms or words you are not familiar with, do not try to rephrase them.\n",
      "    Original query: I want to buy a dress, shoes and gift for my friend's wedding\n",
      "\n",
      "    Rewritten query:\n",
      "\n",
      "OpenAI response: content=\"1. Where can I buy a dress for my friend's wedding?\\n2. Where can I buy shoes for my friend's wedding?\\n3. Where can I buy a gift for my friend's wedding?\\n4. What style of dress should I consider for a wedding?\\n5. What type of shoes are appropriate for a wedding?\\n6. What are some gift ideas for a friend's wedding?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 101, 'total_tokens': 180, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CQ4IGMVvfnRHXYAIX55QMqsj1XYPA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--c85beb8e-4d13-4087-8214-2c2a1a1f0a5a-0' usage_metadata={'input_tokens': 101, 'output_tokens': 79, 'total_tokens': 180, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Create a simple prompt template\n",
    "template = \"\"\"\n",
    " You are a helpful assistant that generates search queries based on a single input query.\n",
    "\n",
    "Perform query decomposition. Given a user question, break it down into distinct sub questions that\n",
    "you need to answer in order to answer the original question.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\n",
    "    Original query: {original_query}\n",
    "\n",
    "    Rewritten query:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "query = \"I want to buy a dress, shoes and gift for my friend's wedding\"\n",
    "\n",
    "# Use the prompt template\n",
    "result = prompt.format(original_query=query)\n",
    "print(result)\n",
    "\n",
    "print(\"OpenAI response:\", llm.invoke(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39bcf48",
   "metadata": {},
   "source": [
    "## Query Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d7f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a helpful assistant that classifies user queries into one of four categories:\n",
      "1. Product — questions about shopping, product details, specifications, availability, or pricing.\n",
      "2. Support — questions about returns, refunds, payments, delivery issues, or customer help.\n",
      "3. Store — questions about store locations, timings, pickup, or availability in stores.\n",
      "4. Account — questions about login, password reset, profile updates, or order history.\n",
      "\n",
      "Return only the category name (Product, Support, Store, or Account).\n",
      "\n",
      "If the query does not clearly fit, choose the closest possible category.\n",
      "\n",
      "Query Category:\n",
      "\n",
      "OpenAI response: content='Product' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 129, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CQ4JUNf2Jnhcd87ws9pyH2oa1zLsH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--32362243-a77f-449a-bb13-a85f006f17a3-0' usage_metadata={'input_tokens': 129, 'output_tokens': 1, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Create a simple prompt template\n",
    "template = \"\"\"\n",
    "You are a helpful assistant that classifies user queries into one of four categories:\n",
    "1. Product — questions about shopping, product details, specifications, availability, or pricing.\n",
    "2. Support — questions about returns, refunds, payments, delivery issues, or customer help.\n",
    "3. Store — questions about store locations, timings, pickup, or availability in stores.\n",
    "4. Account — questions about login, password reset, profile updates, or order history.\n",
    "\n",
    "Return only the category name (Product, Support, Store, or Account).\n",
    "\n",
    "If the query does not clearly fit, choose the closest possible category.\n",
    "\n",
    "Query Category:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "query = \"I want to buy a dress, shoes and gift for my friend's wedding\"\n",
    "\n",
    "# Use the prompt template\n",
    "result = prompt.format(original_query=query)\n",
    "print(result)\n",
    "\n",
    "print(\"OpenAI response:\", llm.invoke(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
